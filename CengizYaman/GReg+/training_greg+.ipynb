{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAgQ45YtmlSK"
      },
      "source": [
        "#Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsZ8j3g8gWIa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import random\n",
        "import math\n",
        "from sklearn.cluster import MiniBatchKMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I4xwn4dmyc4"
      },
      "source": [
        "#Common Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT7rJRPVgab7"
      },
      "outputs": [],
      "source": [
        "class NPYAuxDataset(Dataset):\n",
        "    def __init__(self, npy_file, transform=None):\n",
        "        self.data = np.load(npy_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "def validate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78I9z5vwm7z1"
      },
      "source": [
        "#Loss Terms and Energy Based Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9VBjPyWhoZu"
      },
      "outputs": [],
      "source": [
        "class energy_loss(nn.Module):\n",
        "    def __init__(self, id_threshold, ood_threshold):\n",
        "        super(energy_loss, self).__init__()\n",
        "        self.id_threshold = id_threshold\n",
        "        self.ood_threshold = ood_threshold\n",
        "\n",
        "    def forward(self, id_scores, ood_scores):\n",
        "        id_mask = (id_scores >= self.id_threshold).float()\n",
        "        id_loss = torch.mean(((id_scores - self.id_threshold) * id_mask) ** 2)\n",
        "\n",
        "        ood_mask = (ood_scores <= self.ood_threshold).float()\n",
        "        ood_loss = torch.mean(((self.ood_threshold - ood_scores) * ood_mask) ** 2)\n",
        "\n",
        "        return id_loss + ood_loss\n",
        "\n",
        "class gradient_regularization(nn.Module):\n",
        "    def __init__(self, id_threshold, ood_threshold):\n",
        "        super(gradient_regularization, self).__init__()\n",
        "        self.id_threshold = id_threshold\n",
        "        self.ood_threshold = ood_threshold\n",
        "\n",
        "    def forward(self, id_scores, ood_scores, id_outputs, ood_outputs):\n",
        "        id_score_grads = torch.autograd.grad(outputs=id_scores, inputs=id_outputs,\n",
        "                                           grad_outputs=torch.ones_like(id_scores),\n",
        "                                           retain_graph=True, create_graph=True)[0]\n",
        "        ood_score_grads = torch.autograd.grad(outputs=ood_scores, inputs=ood_outputs,\n",
        "                                            grad_outputs=torch.ones_like(ood_scores),\n",
        "                                            retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        id_grad_norm = torch.norm(id_score_grads.view(id_score_grads.size(0), -1), dim=1)\n",
        "        ood_grad_norm = torch.norm(ood_score_grads.view(ood_score_grads.size(0), -1), dim=1)\n",
        "\n",
        "        id_mask = (id_scores <= self.id_threshold).float()\n",
        "        ood_mask = (ood_scores <= self.ood_threshold).float()\n",
        "\n",
        "        id_grad_loss = torch.mean(id_grad_norm * id_mask)\n",
        "        ood_grad_loss = torch.mean(ood_grad_norm * ood_mask)\n",
        "\n",
        "        return id_grad_loss + ood_grad_loss\n",
        "\n",
        "def energy_based_sampling(aux_dataloader, feature_extractor, model, num_clusters, device):\n",
        "\n",
        "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=1024)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for aux_batch in tqdm(aux_dataloader, desc=\"Partial Fitting\"):\n",
        "            aux_batch = aux_batch.to(device)\n",
        "            batch_features = feature_extractor(aux_batch).cpu().numpy()\n",
        "            kmeans.partial_fit(batch_features)\n",
        "\n",
        "    min_energy_per_cluster = [float(\"inf\")] * num_clusters\n",
        "    max_energy_per_cluster = [float(\"-inf\")] * num_clusters\n",
        "\n",
        "    min_sample_per_cluster = [None] * num_clusters\n",
        "    max_sample_per_cluster = [None] * num_clusters\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for aux_batch in tqdm(aux_dataloader, desc=\"Min/Max Sample Extraction\"):\n",
        "            aux_batch = aux_batch.to(device)\n",
        "            batch_features = feature_extractor(aux_batch).cpu().numpy()\n",
        "            cluster_labels = kmeans.predict(batch_features)\n",
        "\n",
        "            id_outputs = model(aux_batch)\n",
        "            batch_energy_scores = -torch.logsumexp(id_outputs, dim=1).cpu().numpy()\n",
        "\n",
        "            for i, cluster_id in enumerate(cluster_labels):\n",
        "                energy = batch_energy_scores[i]\n",
        "\n",
        "                if energy < min_energy_per_cluster[cluster_id]:\n",
        "                    min_energy_per_cluster[cluster_id] = energy\n",
        "                    min_sample_per_cluster[cluster_id] = aux_batch[i].cpu().numpy()\n",
        "\n",
        "                if energy > max_energy_per_cluster[cluster_id]:\n",
        "                    max_energy_per_cluster[cluster_id] = energy\n",
        "                    max_sample_per_cluster[cluster_id] = aux_batch[i].cpu().numpy()\n",
        "\n",
        "    return min_sample_per_cluster, max_sample_per_cluster\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0G_xr5Jm_9u"
      },
      "source": [
        "#Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zOLq40BjXgo"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        base_model = models.resnet18(pretrained=False)\n",
        "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        out = self.fc(features)\n",
        "        return out\n",
        "\n",
        "    def get_features(self, x):\n",
        "        features = self.features(x)\n",
        "        return features.view(features.size(0), -1)\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        base_model = models.densenet121(pretrained=False)\n",
        "        self.features = base_model.features\n",
        "        self.classifier = nn.Linear(base_model.classifier.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
        "        features = features.view(features.size(0), -1)\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "    def get_features(self, x):\n",
        "        features = self.features(x)\n",
        "        features = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
        "        return features.view(features.size(0), -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Zr9oaBnKZJ"
      },
      "source": [
        "#Model, Datasets and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-H6KJi_jcXU",
        "outputId": "2bd8422a-7718-4b60-90e3-b111643959ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# use either ResNet18 or DenseNet121\n",
        "model = ResNet18(num_classes = 10) # adjust for number of classes\n",
        "model = DenseNet(num_classes = 10)\n",
        "\n",
        "# for training with multiple GPUs\n",
        "model = nn.DataParallel(model)\n",
        "model = model.to(device)\n",
        "model = model.float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLVluu5xje8W"
      },
      "outputs": [],
      "source": [
        "# Transformations\n",
        "transform_aux = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjJjW9ivji7V",
        "outputId": "6882137b-0b61-488f-8023-f467f9f830c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Create datasets\n",
        "cifar100_root = '/path/to/dataset'\n",
        "randomimages300k_root = '/path/to/dataset'\n",
        "\n",
        "cifar10_train = datasets.CIFAR10(root=cifar10_root, train=True, download=True, transform=transform_cifar)\n",
        "cifar10_test = datasets.CIFAR10(root=cifar10_root, train=False, download=True, transform=transform_cifar)\n",
        "cifar100_train = datasets.CIFAR100(root=cifar100_root, train=True, download=True, transform=transform_cifar)\n",
        "cifar100_test = datasets.CIFAR100(root=cifar100_root, train=False, download=True, transform=transform_cifar)\n",
        "randomimages300k_dataset = NPYAuxDataset(randomimages300k_root, transform=transform_aux)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "id_dataloader = DataLoader(cifar10_train, batch_size=batch_size, shuffle=True, num_workers=16)\n",
        "id_test_dataloader = DataLoader(cifar10_test, batch_size=batch_size, shuffle=False, num_workers=16)\n",
        "aux_dataloader = DataLoader(randomimages300k_dataset, batch_size=batch_size, shuffle=True, num_workers=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "Rr5BSBpWpAXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX0TfvItjrQJ"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "energy_l = energy_loss(id_threshold=-27, ood_threshold=-5)\n",
        "gradient_l = gradient_regularization(id_threshold=-27, ood_threshold=-5)\n",
        "criterion_ce = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEBRDxMjnSLU"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNTPhFWcj9Cr",
        "outputId": "0f0c04a4-03c2-4355-f994-8efd4d698f40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.83it/s]    \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.12it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 48.10it/s]                                                               \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:05<00:00, 37.24it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:36<00:00, 48.39it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.18it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 48.02it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.05it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.56it/s]                                                               \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.14it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.79it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.14it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 48.28it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:05<00:00, 37.22it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.78it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.01it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 47.88it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.10it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 48.31it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:05<00:00, 37.31it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 48.17it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.19it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 48.16it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:05<00:00, 37.31it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 47.99it/s]                                                               \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.18it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:37<00:00, 47.86it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.19it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.69it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.16it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.51it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.06it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.65it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.15it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.77it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.11it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.64it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.17it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.41it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 36.98it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.59it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 36.99it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.58it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 36.96it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.43it/s]                                                                 \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.00it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.63it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.81it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.76it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.06it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.37it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.83it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.44it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.63it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.64it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:06<00:00, 37.00it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.51it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.70it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.31it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.79it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.27it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.74it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.31it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.90it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.26it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.83it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.16it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.85it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.41it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.82it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.37it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.88it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.38it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.87it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.34it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.84it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.40it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.70it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.45it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.85it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.58it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.72it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.33it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.63it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.37it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.68it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.19it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.73it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.02it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.65it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.33it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.72it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.27it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.72it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.38it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.83it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:38<00:00, 47.39it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.69it/s]\n",
            "Partial Fitting: 100%|██████████| 4688/4688 [01:39<00:00, 47.17it/s]                                                                \n",
            "Min/Max Sample Extraction: 100%|██████████| 4688/4688 [02:07<00:00, 36.74it/s]\n",
            "                                                                                                                                    \r"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_ce_loss</td><td>█▅▄▄▄▃▅▃▃▃▃▂▂▂▂▂▂▂▃▂▂▂▁▁▁▁▁▁▁▁▂▂▂▁▁▁▁▂▁▁</td></tr><tr><td>avg_energy_loss</td><td>▃▃▂▂▂▂█▂▃▂▂▁▂▁▁▁▂▁▂▂▁▂▁▁▁▁▁▂▂▁▁▂▂▁▁▂▁▂▁▁</td></tr><tr><td>avg_gradient_loss</td><td>▆▁▁▅▃▂▅▃▂▄▃▄▃▃▃▅▃▄▂▃▅▃▃▄▄▃▃▄▄▅▄▅▄▆▄▃▆█▇▅</td></tr><tr><td>avg_total_loss</td><td>▆▅▃▄▃▃█▃▂▃▂▂▂▂▂▂▂▂▁▃▁▂▁▁▁▁▁▁▂▂▃▂▂▁▁▂▁▂▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▂▃▃▄▄▂▅▅▅▆▆▆▃▇▇▅▆▆▆▇▇▇█▅██▇█▇▇▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_ce_loss</td><td>2.38184</td></tr><tr><td>avg_energy_loss</td><td>4.32451</td></tr><tr><td>avg_gradient_loss</td><td>0.17724</td></tr><tr><td>avg_total_loss</td><td>2.99154</td></tr><tr><td>learning_rate</td><td>0.1</td></tr><tr><td>validation_accuracy</td><td>38.13</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ResNet18 cifar100</strong> at: <a href='https://wandb.ai/cengizcenkkerem-metu-middle-east-technical-university/Greg%2B/runs/s1tkvcpi' target=\"_blank\">https://wandb.ai/cengizcenkkerem-metu-middle-east-technical-university/Greg%2B/runs/s1tkvcpi</a><br> View project at: <a href='https://wandb.ai/cengizcenkkerem-metu-middle-east-technical-university/Greg%2B' target=\"_blank\">https://wandb.ai/cengizcenkkerem-metu-middle-east-technical-university/Greg%2B</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250111_073644-s1tkvcpi/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_ce_loss = 0.0\n",
        "    total_energy_loss = 0.0\n",
        "    total_gradient_loss = 0.0\n",
        "    num_batches = 0\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Perform energy-based sampling at the start of the epoch\n",
        "    all_aux_features = []\n",
        "    all_aux_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for aux_batch in tqdm(aux_dataloader, desc=\"Processing Aux Data\", leave=False):\n",
        "            aux_batch = aux_batch.to(device)\n",
        "            aux_features = model.module.get_features(aux_batch)\n",
        "            aux_outputs = model.module.fc(aux_features)\n",
        "            all_aux_features.append(aux_features.cpu().numpy())\n",
        "            all_aux_outputs.append(-torch.logsumexp(aux_outputs, dim=1).cpu().numpy())\n",
        "\n",
        "    # Stack all auxiliary features and energy scores\n",
        "    all_aux_features = np.vstack(all_aux_features)\n",
        "    all_aux_energy_scores = np.concatenate(all_aux_outputs)\n",
        "\n",
        "    # Perform clustering and sampling\n",
        "    min_energy_samples, max_energy_samples = energy_based_sampling(\n",
        "    aux_dataloader=aux_dataloader,\n",
        "    feature_extractor=lambda x: model.module.get_features(x),\n",
        "    model=model.module,  # Use the underlying model\n",
        "    num_clusters=batch_size,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "    # Prepare auxiliary samples for training (already matches batch size)\n",
        "    min_energy_samples = [x for x in min_energy_samples if x is not None]\n",
        "    max_energy_samples = [x for x in max_energy_samples if x is not None]\n",
        "\n",
        "    min_energy_samples = np.stack(min_energy_samples, axis=0)\n",
        "    min_energy_samples = torch.from_numpy(min_energy_samples).float().to(device)\n",
        "\n",
        "    max_energy_samples = np.stack(max_energy_samples, axis=0)\n",
        "    max_energy_samples = torch.from_numpy(max_energy_samples).float().to(device)\n",
        "\n",
        "    min_energy_samples.requires_grad = True\n",
        "    max_energy_samples.requires_grad = True\n",
        "\n",
        "    batch_loop = tqdm(id_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "\n",
        "    for id_inputs, id_labels in batch_loop:\n",
        "        # Directly use the pre-sampled auxiliary data for the batch\n",
        "        id_inputs, id_labels = id_inputs.to(device), id_labels.to(device)\n",
        "        id_inputs.requires_grad = True\n",
        "\n",
        "        # Forward pass\n",
        "        id_outputs = model(id_inputs)\n",
        "        aux_min_outputs = model(min_energy_samples)\n",
        "        aux_max_outputs = model(max_energy_samples)\n",
        "\n",
        "        # Compute energy scores\n",
        "        id_energy_scores = -torch.logsumexp(id_outputs, dim=1)\n",
        "        aux_min_energy_scores = -torch.logsumexp(aux_min_outputs, dim=1)\n",
        "        aux_max_energy_scores = -torch.logsumexp(aux_max_outputs, dim=1)\n",
        "\n",
        "        # Compute losses\n",
        "        ce_loss_value = criterion_ce(id_outputs, id_labels)\n",
        "        energy_loss_value = energy_l(id_energy_scores, aux_min_energy_scores)\n",
        "        gradient_loss_value = gradient_l(\n",
        "            id_energy_scores, aux_max_energy_scores, id_inputs, max_energy_samples\n",
        "        )\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = ce_loss_value + 0.1 * energy_loss_value + 1.0 * gradient_loss_value\n",
        "\n",
        "        # Accumulate losses\n",
        "        total_ce_loss += ce_loss_value.item()\n",
        "        total_energy_loss += energy_loss_value.item()\n",
        "        total_gradient_loss += gradient_loss_value.item()\n",
        "        epoch_loss += total_loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        # Optimization step\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loop.set_postfix({\n",
        "            \"CE Loss\": ce_loss_value.item(),\n",
        "            \"Energy Loss\": energy_loss_value.item(),\n",
        "            \"Grad Loss\": gradient_loss_value.item(),\n",
        "            \"Total Loss\": total_loss.item()\n",
        "        })\n",
        "\n",
        "\n",
        "    # Calculate average losses\n",
        "    avg_ce_loss = total_ce_loss / num_batches\n",
        "    avg_energy_loss = total_energy_loss / num_batches\n",
        "    avg_gradient_loss = total_gradient_loss / num_batches\n",
        "    avg_total_loss = epoch_loss / num_batches\n",
        "\n",
        "    # Validate\n",
        "    val_accuracy = validate(model, id_test_dataloader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qpFW6mJkGbt"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), \"/path/to/save/model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDGx6y5SoFvu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EAgQ45YtmlSK",
        "7I4xwn4dmyc4",
        "78I9z5vwm7z1",
        "P0G_xr5Jm_9u",
        "M4Zr9oaBnKZJ",
        "XEBRDxMjnSLU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}