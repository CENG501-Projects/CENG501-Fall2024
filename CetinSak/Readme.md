# How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model

This readme file is an outcome of the [CENG501 (Spring 2024)](https://ceng.metu.edu.tr/~skalkan/DL/) project for reproducing a paper without an implementation. See [CENG501 (Spring 42) Project List](https://github.com/CENG501-Projects/CENG501-Fall2024) for a complete list of all paper reproduction projects.

# 1. Introduction

@TODO: Introduce the paper (inc. where it is published) and describe your goal (reproducibility).

@TODO: Convert bullet points to paragraphs 
- The paper is published at Proceedings of Machine Learning Research.
- Our goal is to reproduce the paper and results.


## 1.1. Paper summary

@TODO: Summarize the paper, the method & its contributions in relation with the existing literature.

# 2. The method and our interpretation

## 2.1. The original method

@TODO: Explain the original method.

## 2.2. Our interpretation

@TODO: Explain the parts that were not clearly explained in the original paper and how you interpreted them.

# 3. Experiments and results

## 3.1. Experimental setup

@TODO: Describe the setup of the original paper and whether you changed any settings.

## 3.2. Running the code

@TODO: Explain your code & directory structure and how other people can run it.

## 3.3. Results

@TODO: Present your results and compare them to the original paper. Please number your figures & tables as if this is a paper.

# 4. Conclusion

@TODO: Discuss the paper in relation to the results in the paper and your results.

# 5. References

@TODO: Provide your references here.

Main Paper: `How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model`
```bibtex
@InProceedings{pmlr-v235-tomasini24a,
  title = 	 {How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model},
  author =       {Tomasini, Umberto Maria and Wyart, Matthieu},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {48369--48389},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/tomasini24a/tomasini24a.pdf},
}
```

Random Hierarchy Model Base Implementation From: `How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model`
```bibtex
@article{Cagnetta_2024,
   title={How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model},
   volume={14},
   ISSN={2160-3308},
   url={http://dx.doi.org/10.1103/PhysRevX.14.031001},
   DOI={10.1103/physrevx.14.031001},
   number={3},
   journal={Physical Review X},
   publisher={American Physical Society (APS)},
   author={Cagnetta, Francesco and Petrini, Leonardo and Tomasini, Umberto M. and Favero, Alessandro and Wyart, Matthieu},
   year={2024},
   month=jul }

```

CIFAR 10 Dataset From: `Learning Multiple Layers of Features from Tiny Images`
```bibtex
@inproceedings{Krizhevsky2009LearningML,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:18268744}
}
```

Model Implementations (VGG ResNet EfficientNetB0) WILL be from: [diffeo-sota repository](https://github.com/leonardopetrini/diffeo-sota/tree/main/models)

@TODO: Authors requested permission from Petrini et al., we should request permission too.

# Contact

Burak Erinç Çetin - erinc.cetin@metu.edu.tr
Emin Sak - sak.emin@metu.edu.tr

@TODO: Provide your names & email addresses and any other info with which people can contact you.
