# Experiment 3B - Diffeo Sensitivity of LCN Networks
[srhm]
num_features = [3,6,9,12]
m = "num_features"
s = 2
s0 = [0,1,2,4]
num_layers = [2,3]
num_classes = "num_features"
input_format = "onehot" # can be decimal, binary, pairs or onehot
whitening = 0
diffeo_retry_count=1
synonym_retry_count=1
seed_diffeo=2 # Diffeo exchange at layer 2
seed_synonym='nil'
sensitivity_stop_ratio = 0.1
p='nil'

[model]
net = "cnn" # can be cnn, fcn or lcn
random_features = 0
width = 512
batch_norm = 0
bias = 0

[optimizer]
loss = "cross_entropy"
optim = "sgd"
scheduler = "cosineannealing"
lr = 0.01
momentum = 0.9
weight_decay = 5e-4
reg_type = "l2"
epochs = 256
zero_loss_epochs = 0
zero_loss_threshold = 0.01
rescale_epochs = 0
alpha = 1.0

[observables]
stability = 0 # 1 to compute it at every checkpoint, 2 at the end of training
clustering_error = 0
locality = 0

[saving]
save_init_net=1
save_best_net=1
save_last_net=1
save_dynamics=1
pickle = "outputs/output.pkl"
output = "outputs/output.pkl"

[pytorch]
device = "cpu"
dtype = "float32"

[seeds]
seed_init = 0 # seed random-hierarchy-model
seed_net = -1 # network initalisation
seed_trainset = -1 # training sample

[dataset]
dataset = "srhm"
ptr = 0.8 # Fraction of training points
pte = 0.2 # Fraction of test points
batch_size = 4
scale_batch_size = 0

[auxiliary]
background_noise = 0
auto_regression = 0