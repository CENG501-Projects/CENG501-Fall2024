[srhm]
num_features = [4,6,8,10]
m = "num_features"
s = 2
s0 = 0
num_layers = [3, 2]
num_classes = "num_features"
input_format = "onehot" # can be decimal, binary, pairs or onehot
whitening = 0
diffeo_retry_count=1
synonym_retry_count=1
seed_diffeo='nil'
seed_synonym='nil'
sensitivity_stop_ratio = 'nil'
p='nil'
test_acc_stop = 0.9

[model]
net = "lcn" # can be cnn, fcn or lcn
random_features = 0
width = 512
batch_norm = 0
bias = 0

[optimizer]
loss = "cross_entropy"
optim = "sgd"
scheduler = "cosineannealing"
lr = 0.01
momentum = 0.9
weight_decay = 5e-4
reg_type = "l2"
epochs = 256
zero_loss_epochs = 0
zero_loss_threshold = 0.01
rescale_epochs = 0
alpha = 1.0

[observables]
stability = 0 # 1 to compute it at every checkpoint, 2 at the end of training
clustering_error = 0
locality = 0

[saving]
save_init_net=1
save_best_net=1
save_last_net=1
save_dynamics=1
pickle = "outputs/output.pkl"
output = "outputs/output.pkl"

[pytorch]
device = "cpu"
dtype = "float32"

[seeds]
seed_init = 0 # seed random-hierarchy-model
seed_net = -1 # network initalisation
seed_trainset = -1 # training sample

[dataset]
dataset = "srhm"
ptr = 0.8 # Fraction of training points
pte = 0.2 # Fraction of test points
batch_size = 4
scale_batch_size = 0

[auxiliary]
background_noise = 0
auto_regression = 0