[srhm]
num_features = 2
m = 2
s = 2
num_layers = 2
num_classes = -1
input_format = onehot # can be decimal, binary, pairs or onehot
whitening = 

[model]
net = cnn # can be cnn, fcn or lcn
random_features = 0
width = 64
net_layers = 3
filter_size = 2
stride = 2
batch_norm = 0
bias = 1

[optimizer]
loss = cross_entropy
optim = sgd
scheduler = cosineannealing
lr = 0.1
momentum = 0.9
weight_decay = 5e-4
reg_type = l2
epochs = 250
zero_loss_epochs = 0
zero_loss_threshold = 0.01
rescale_epochs = 0
alpha = 1.0

[observables]
stability = 0 # 1 to compute it at every checkpoint, 2 at the end of training
clustering_error = 0
locality = 0

[saving]
save_init_net=1
save_best_net=1
save_last_net=1
save_dynamics=0
pickle_path = None
output_path = None

[pytorch]
device = cpu
dtype = float32

[seeds]
seed_init = 0 # seed random-hierarchy-model
seed_net = -1 # network initalisation
seed_trainset = -1 # training sample

[dataset]
dataset = hier1
ptr = 0.8 # Fraction of training points
pte = 0.2 # Fraction of test points
batch_size = 128
scale_batch_size = 0

[auxiliary]
background_noise = 0