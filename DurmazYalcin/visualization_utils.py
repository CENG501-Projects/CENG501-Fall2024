import numpy as np
import os
import h5py
import time
import cv2
import torch

##### Generated by ChatGPT
def torch_to_cv2_image(torch_image):
    # Step 1: Convert torch tensor to numpy array
    np_image = torch_image.permute(1, 2, 0).cpu().numpy().astype(np.uint8)  # Change [C, H, W] to [H, W, C]
    
    # Step 3: Convert RGB to BGR
    cv2_image = cv2.cvtColor(np_image, cv2.COLOR_RGB2BGR)
    
    return cv2_image


################################################################################
##### We have adopted the event visualizer from the amazing work of E-RAFT #####
################################################################################
def plot_points_on_background(points_coordinates,
                              background,
                              points_color=[0, 0, 255]):
    """
    Args:
        points_coordinates: array of (y, x) points coordinates
                            of size (number_of_points x 2).
        background: (3 x height x width)
                    gray or color image uint8.
        color: color of points [red, green, blue] uint8.
    """
    if not (len(background.size()) == 3 and background.size(0) == 3):
        raise ValueError('background should be (color x height x width).')
    _, height, width = background.size()
    background_with_points = background.clone()
    y, x = points_coordinates.transpose(0, 1)
    if len(x) > 0 and len(y) > 0: # There can be empty arrays!
        x_min, x_max = x.min(), x.max()
        y_min, y_max = y.min(), y.max()
        if not (x_min >= 0 and y_min >= 0 and x_max < width and y_max < height):
            raise ValueError('points coordinates are outsize of "background" '
                             'boundaries.')
        background_with_points[:, y, x] = torch.Tensor(points_color).type_as(
            background).unsqueeze(-1)
    return background_with_points

################################################################################
##### We have adopted the event visualizer from the amazing work of E-RAFT #####
################################################################################
def events_to_event_image(event_sequence):
    width  = 346
    height = 260
    polarity   = event_sequence[:, 3] == -1.0
    x_negative = event_sequence[~polarity, 0].astype(int)
    y_negative = event_sequence[~polarity, 1].astype(int)
    x_positive = event_sequence[polarity, 0].astype(int)
    y_positive = event_sequence[polarity, 1].astype(int)

    positive_histogram, _, _ = np.histogram2d(
        x_positive,
        y_positive,
        bins=(width, height),
        range=[[0, width], [0, height]])
    negative_histogram, _, _ = np.histogram2d(
        x_negative,
        y_negative,
        bins=(width, height),
        range=[[0, width], [0, height]])

    # Red -> Negative Events
    red = np.transpose((negative_histogram >= positive_histogram) & (negative_histogram != 0))
    # Blue -> Positive Events
    blue = np.transpose(positive_histogram > negative_histogram)
    
    # Create a background image
    background = torch.full((3, height, width), 255).byte()
    
    # Visaulize the events
    points_on_background = plot_points_on_background(
        torch.nonzero(torch.from_numpy(red.astype(np.uint8))), background,
        [255, 0, 0])
    points_on_background = plot_points_on_background(
        torch.nonzero(torch.from_numpy(blue.astype(np.uint8))),
        points_on_background, [0, 0, 255])
    
    # Convert image into opencv format
    points_on_background = torch_to_cv2_image(points_on_background)
    
    # Visualization is ready
    return points_on_background

def events_to_image(x,y,p,width,height):
    polarity   = (p == 1)
    x_negative = x[~polarity].astype(int)
    y_negative = y[~polarity].astype(int)
    x_positive = x[polarity].astype(int)
    y_positive = y[polarity].astype(int)

    positive_histogram, _, _ = np.histogram2d(
        x_positive,
        y_positive,
        bins=(width, height),
        range=[[0, width], [0, height]])
    negative_histogram, _, _ = np.histogram2d(
        x_negative,
        y_negative,
        bins=(width, height),
        range=[[0, width], [0, height]])

    # Red -> Negative Events
    red = np.transpose((negative_histogram >= positive_histogram) & (negative_histogram != 0))
    # Blue -> Positive Events
    blue = np.transpose(positive_histogram > negative_histogram)
    
    # Create a background image
    background = torch.full((3, height, width), 255).byte()
    
    # Visaulize the events
    points_on_background = plot_points_on_background(
        torch.nonzero(torch.from_numpy(red.astype(np.uint8))), background,
        [255, 0, 0])
    points_on_background = plot_points_on_background(
        torch.nonzero(torch.from_numpy(blue.astype(np.uint8))),
        points_on_background, [0, 0, 255])
    
    # Convert image into opencv format
    points_on_background = torch_to_cv2_image(points_on_background)
    
    return points_on_background



###############################################################################
##### We have adopted the flow visualizer from the amazing work of E-RAFT #####
###############################################################################
def make_colorwheel():
    """
    Generates a color wheel for optical flow visualization as presented in:
        Baker et al. "A Database and Evaluation Methodology for Optical Flow" (ICCV, 2007)
        URL: http://vision.middlebury.edu/flow/flowEval-iccv07.pdf

    Code follows the original C++ source code of Daniel Scharstein.
    Code follows the the Matlab source code of Deqing Sun.

    Returns:
        np.ndarray: Color wheel
    """

    RY = 15
    YG = 6
    GC = 4
    CB = 11
    BM = 13
    MR = 6

    ncols = RY + YG + GC + CB + BM + MR
    colorwheel = np.zeros((ncols, 3))
    col = 0

    # RY
    colorwheel[0:RY, 0] = 255
    colorwheel[0:RY, 1] = np.floor(255*np.arange(0,RY)/RY)
    col = col+RY
    # YG
    colorwheel[col:col+YG, 0] = 255 - np.floor(255*np.arange(0,YG)/YG)
    colorwheel[col:col+YG, 1] = 255
    col = col+YG
    # GC
    colorwheel[col:col+GC, 1] = 255
    colorwheel[col:col+GC, 2] = np.floor(255*np.arange(0,GC)/GC)
    col = col+GC
    # CB
    colorwheel[col:col+CB, 1] = 255 - np.floor(255*np.arange(CB)/CB)
    colorwheel[col:col+CB, 2] = 255
    col = col+CB
    # BM
    colorwheel[col:col+BM, 2] = 255
    colorwheel[col:col+BM, 0] = np.floor(255*np.arange(0,BM)/BM)
    col = col+BM
    # MR
    colorwheel[col:col+MR, 2] = 255 - np.floor(255*np.arange(MR)/MR)
    colorwheel[col:col+MR, 0] = 255
    return colorwheel

###############################################################################
##### We have adopted the flow visualizer from the amazing work of E-RAFT #####
###############################################################################
def flow_uv_to_colors(u, v, convert_to_bgr=False):
    """
    Applies the flow color wheel to (possibly clipped) flow components u and v.

    According to the C++ source code of Daniel Scharstein
    According to the Matlab source code of Deqing Sun

    Args:
        u (np.ndarray): Input horizontal flow of shape [H,W]
        v (np.ndarray): Input vertical flow of shape [H,W]
        convert_to_bgr (bool, optional): Convert output image to BGR. Defaults to False.

    Returns:
        np.ndarray: Flow visualization image of shape [H,W,3]
    """
    flow_image = np.zeros((u.shape[0], u.shape[1], 3), np.uint8)
    colorwheel = make_colorwheel()  # shape [55x3]
    ncols = colorwheel.shape[0]
    rad = np.sqrt(np.square(u) + np.square(v))
    a = np.arctan2(-v, -u)/np.pi
    fk = (a+1) / 2*(ncols-1)
    k0 = np.floor(fk).astype(np.int32)
    k1 = k0 + 1
    k1[k1 == ncols] = 0
    f = fk - k0
    for i in range(colorwheel.shape[1]):
        tmp = colorwheel[:,i]
        col0 = tmp[k0] / 255.0
        col1 = tmp[k1] / 255.0
        col = (1-f)*col0 + f*col1
        idx = (rad <= 1)
        col[idx]  = 1 - rad[idx] * (1-col[idx])
        col[~idx] = col[~idx] * 0.75   # out of range
        # Note the 2-i => BGR instead of RGB
        ch_idx = 2-i if convert_to_bgr else i
        flow_image[:,:,ch_idx] = np.floor(255 * col)
    return flow_image

###############################################################################
##### We have adopted the flow visualizer from the amazing work of E-RAFT #####
###############################################################################
def flow_to_image(flow_uv, clip_flow=None, convert_to_bgr=False):
    """
    Expects a two dimensional flow image of shape.

    Args:
        flow_uv (np.ndarray): Flow UV image of shape [H,W,2]
        clip_flow (float, optional): Clip maximum of flow values. Defaults to None.
        convert_to_bgr (bool, optional): Convert output image to BGR. Defaults to False.

    Returns:
        np.ndarray: Flow visualization image of shape [H,W,3]
    """
    assert flow_uv.ndim == 3, 'input flow must have three dimensions'
    assert flow_uv.shape[2] == 2, 'input flow must have shape [H,W,2]'
    if clip_flow is not None:
        flow_uv = np.clip(flow_uv, 0, clip_flow)
    u = flow_uv[:,:,0]
    v = flow_uv[:,:,1]
    rad = np.sqrt(np.square(u) + np.square(v))
    rad_max = np.max(rad)
    epsilon = 1e-5
    u = u / (rad_max + epsilon)
    v = v / (rad_max + epsilon)
    return flow_uv_to_colors(u, v, convert_to_bgr)

if __name__ == "__main__":
    # Path to data
    path_to_data = os.path.join("/home/hakito/datasets/event_data", "outdoor_day1_data.hdf5")

    # Load the data
    hdf_file = h5py.File(path_to_data, "r")

    # Check what is inside the data
    print("Top-level groups:", list(hdf_file.keys()))

    # Load grayscale data
    gray_image_data = hdf_file['davis']['left']['image_raw']

    # Load event daata
    events_data = hdf_file['davis']['left']['events']

    # Load event to image indexes
    image_raw_event_inds = hdf_file['davis']['left']['image_raw_event_inds']

    # for idx in range(1,gray_image_data.shape[0]-1):
    for idx in range(3250,3500):
        # Get the grayscale image
        img_frame = gray_image_data[idx]
        
        # Apply histogram equalization
        img_frame = cv2.equalizeHist(img_frame)
    
        img_frame = cv2.cvtColor(img_frame, cv2.COLOR_RGB2BGR)
        
        # Get the related events
        related_events = events_data[image_raw_event_inds[idx-1]:image_raw_event_inds[idx+1],:]

        # Visualize the events
        event_image = events_to_event_image(related_events)
        
        # Concatenate images for a better visualization
        out_img = cv2.hconcat([img_frame, event_image])
        
        # Show the image
        cv2.imshow("out_img", out_img)
        key = cv2.waitKey(1)
        if key == ord("q") or key == ord("Q"):
            break
        cv2.imwrite("ExampleFrames/" + str(idx) + ".png", out_img)

    
    
class txtAdder():
    def __init__(self):
        self.font_scale = 0.8
        self.thickness = 3
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        
        self.color = (10,100,80)

    def put_txt(self,img,exp, position = (10, 40)):
        cv2.putText(img, exp, position, self.font, self.font_scale, self.color, self.thickness, cv2.LINE_AA)
        return img